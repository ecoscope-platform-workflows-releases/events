# AUTOGENERATED BY ECOSCOPE-WORKFLOWS; see fingerprint in README.md for details


# ruff: noqa: E402

# %% [markdown]
# # Events
# TODO: top level description

# %% [markdown]
# ## Imports

import os

from ecoscope_workflows_core.tasks.config import set_string_var as set_string_var
from ecoscope_workflows_core.tasks.config import (
    set_workflow_details as set_workflow_details,
)
from ecoscope_workflows_core.tasks.filter import (
    get_timezone_from_time_range as get_timezone_from_time_range,
)
from ecoscope_workflows_core.tasks.filter import set_time_range as set_time_range
from ecoscope_workflows_core.tasks.groupby import set_groupers as set_groupers
from ecoscope_workflows_core.tasks.groupby import split_groups as split_groups
from ecoscope_workflows_core.tasks.io import persist_text as persist_text
from ecoscope_workflows_core.tasks.io import set_er_connection as set_er_connection
from ecoscope_workflows_core.tasks.results import (
    create_map_widget_single_view as create_map_widget_single_view,
)
from ecoscope_workflows_core.tasks.results import (
    create_plot_widget_single_view as create_plot_widget_single_view,
)
from ecoscope_workflows_core.tasks.results import gather_dashboard as gather_dashboard
from ecoscope_workflows_core.tasks.results import (
    merge_widget_views as merge_widget_views,
)
from ecoscope_workflows_core.tasks.skip import (
    any_dependency_skipped as any_dependency_skipped,
)
from ecoscope_workflows_core.tasks.skip import any_is_empty_df as any_is_empty_df
from ecoscope_workflows_core.tasks.skip import never as never
from ecoscope_workflows_core.tasks.transformation import (
    add_temporal_index as add_temporal_index,
)
from ecoscope_workflows_core.tasks.transformation import (
    convert_values_to_timezone as convert_values_to_timezone,
)
from ecoscope_workflows_core.tasks.transformation import (
    extract_value_from_json_column as extract_value_from_json_column,
)
from ecoscope_workflows_core.tasks.transformation import map_columns as map_columns
from ecoscope_workflows_core.tasks.transformation import sort_values as sort_values
from ecoscope_workflows_ext_ecoscope.tasks.analysis import (
    calculate_feature_density as calculate_feature_density,
)
from ecoscope_workflows_ext_ecoscope.tasks.analysis import (
    create_meshgrid as create_meshgrid,
)
from ecoscope_workflows_ext_ecoscope.tasks.io import get_events as get_events
from ecoscope_workflows_ext_ecoscope.tasks.io import (
    get_spatial_features_group as get_spatial_features_group,
)
from ecoscope_workflows_ext_ecoscope.tasks.results import (
    create_point_layer as create_point_layer,
)
from ecoscope_workflows_ext_ecoscope.tasks.results import (
    create_polygon_layer as create_polygon_layer,
)
from ecoscope_workflows_ext_ecoscope.tasks.results import draw_ecomap as draw_ecomap
from ecoscope_workflows_ext_ecoscope.tasks.results import (
    draw_pie_chart as draw_pie_chart,
)
from ecoscope_workflows_ext_ecoscope.tasks.results import (
    draw_time_series_bar_chart as draw_time_series_bar_chart,
)
from ecoscope_workflows_ext_ecoscope.tasks.results import set_base_maps as set_base_maps
from ecoscope_workflows_ext_ecoscope.tasks.skip import (
    all_geometry_are_none as all_geometry_are_none,
)
from ecoscope_workflows_ext_ecoscope.tasks.transformation import (
    add_spatial_index as add_spatial_index,
)
from ecoscope_workflows_ext_ecoscope.tasks.transformation import (
    apply_classification as apply_classification,
)
from ecoscope_workflows_ext_ecoscope.tasks.transformation import (
    apply_color_map as apply_color_map,
)
from ecoscope_workflows_ext_ecoscope.tasks.transformation import (
    apply_reloc_coord_filter as apply_reloc_coord_filter,
)
from ecoscope_workflows_ext_ecoscope.tasks.transformation import (
    drop_nan_values_by_column as drop_nan_values_by_column,
)
from ecoscope_workflows_ext_ecoscope.tasks.transformation import (
    extract_spatial_grouper_feature_group_ids as extract_spatial_grouper_feature_group_ids,
)
from ecoscope_workflows_ext_ecoscope.tasks.transformation import (
    resolve_spatial_feature_groups_for_spatial_groupers as resolve_spatial_feature_groups_for_spatial_groupers,
)

# %% [markdown]
# ## Workflow Details

# %%
# parameters

workflow_details_params = dict(
    name=...,
    description=...,
    image_url=...,
)

# %%
# call the task


workflow_details = (
    set_workflow_details.set_task_instance_id("workflow_details")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(**workflow_details_params)
    .call()
)


# %% [markdown]
# ## Data Source

# %%
# parameters

er_client_name_params = dict(
    data_source=...,
)

# %%
# call the task


er_client_name = (
    set_er_connection.set_task_instance_id("er_client_name")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(**er_client_name_params)
    .call()
)


# %% [markdown]
# ## Time Range

# %%
# parameters

time_range_params = dict(
    since=...,
    until=...,
    timezone=...,
)

# %%
# call the task


time_range = (
    set_time_range.set_task_instance_id("time_range")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(time_format="%d %b %Y %H:%M:%S", **time_range_params)
    .call()
)


# %% [markdown]
# ## Extract Timezone Selection

# %%
# parameters

get_timezone_params = dict()

# %%
# call the task


get_timezone = (
    get_timezone_from_time_range.set_task_instance_id("get_timezone")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(time_range=time_range, **get_timezone_params)
    .call()
)


# %% [markdown]
# ## Event Types

# %%
# parameters

get_events_data_params = dict(
    event_types=...,
    include_null_geometry=...,
)

# %%
# call the task


get_events_data = (
    get_events.set_task_instance_id("get_events_data")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        client=er_client_name,
        time_range=time_range,
        event_columns=[
            "id",
            "time",
            "event_type",
            "event_category",
            "reported_by",
            "serial_number",
            "geometry",
        ],
        raise_on_empty=False,
        include_details=False,
        include_updates=False,
        include_related_events=False,
        include_display_values=True,
        **get_events_data_params,
    )
    .call()
)


# %% [markdown]
# ## Convert to timezone

# %%
# parameters

convert_to_user_timezone_params = dict()

# %%
# call the task


convert_to_user_timezone = (
    convert_values_to_timezone.set_task_instance_id("convert_to_user_timezone")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=get_events_data,
        timezone=get_timezone,
        columns=["time"],
        **convert_to_user_timezone_params,
    )
    .call()
)


# %% [markdown]
# ## Extract reported_by_name from Events

# %%
# parameters

extract_reported_by_params = dict()

# %%
# call the task


extract_reported_by = (
    extract_value_from_json_column.set_task_instance_id("extract_reported_by")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=convert_to_user_timezone,
        column_name="reported_by",
        field_name_options=["name"],
        output_type="str",
        output_column_name="reported_by_name",
        **extract_reported_by_params,
    )
    .call()
)


# %% [markdown]
# ## Group Data

# %%
# parameters

groupers_params = dict(
    groupers=...,
)

# %%
# call the task


groupers = (
    set_groupers.set_task_instance_id("groupers")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(**groupers_params)
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

spatial_group_ids_params = dict()

# %%
# call the task


spatial_group_ids = (
    extract_spatial_grouper_feature_group_ids.set_task_instance_id("spatial_group_ids")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(groupers=groupers, **spatial_group_ids_params)
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

fetch_all_spatial_feature_groups_params = dict()

# %%
# call the task


fetch_all_spatial_feature_groups = (
    get_spatial_features_group.set_task_instance_id("fetch_all_spatial_feature_groups")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(client=er_client_name, **fetch_all_spatial_feature_groups_params)
    .map(argnames=["spatial_features_group_id"], argvalues=spatial_group_ids)
)


# %% [markdown]
# ##

# %%
# parameters

resolved_groupers_params = dict()

# %%
# call the task


resolved_groupers = (
    resolve_spatial_feature_groups_for_spatial_groupers.set_task_instance_id(
        "resolved_groupers"
    )
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            never,
        ],
        unpack_depth=1,
    )
    .partial(
        groupers=groupers,
        spatial_feature_groups=fetch_all_spatial_feature_groups,
        **resolved_groupers_params,
    )
    .call()
)


# %% [markdown]
# ## Event Location Filter

# %%
# parameters

filter_events_params = dict(
    bounding_box=...,
    filter_point_coords=...,
)

# %%
# call the task


filter_events = (
    apply_reloc_coord_filter.set_task_instance_id("filter_events")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=extract_reported_by,
        roi_gdf=None,
        roi_name=None,
        reset_index=True,
        **filter_events_params,
    )
    .call()
)


# %% [markdown]
# ## Add temporal index to Events

# %%
# parameters

events_add_temporal_index_params = dict()

# %%
# call the task


events_add_temporal_index = (
    add_temporal_index.set_task_instance_id("events_add_temporal_index")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=filter_events,
        time_col="time",
        groupers=resolved_groupers,
        cast_to_datetime=True,
        format="mixed",
        **events_add_temporal_index_params,
    )
    .call()
)


# %% [markdown]
# ## Add spatial index to Events

# %%
# parameters

events_add_spatial_index_params = dict()

# %%
# call the task


events_add_spatial_index = (
    add_spatial_index.set_task_instance_id("events_add_spatial_index")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        gdf=events_add_temporal_index,
        groupers=resolved_groupers,
        **events_add_spatial_index_params,
    )
    .call()
)


# %% [markdown]
# ## Events Colormap

# %%
# parameters

events_colormap_params = dict()

# %%
# call the task


events_colormap = (
    apply_color_map.set_task_instance_id("events_colormap")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=events_add_spatial_index,
        input_column_name="event_type",
        colormap="tab20b",
        output_column_name="event_type_colormap",
        **events_colormap_params,
    )
    .call()
)


# %% [markdown]
# ## Set Bar Chart Title

# %%
# parameters

set_bar_chart_title_params = dict()

# %%
# call the task


set_bar_chart_title = (
    set_string_var.set_task_instance_id("set_bar_chart_title")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(var="Events Bar Chart", **set_bar_chart_title_params)
    .call()
)


# %% [markdown]
# ## Set Events Map Title

# %%
# parameters

set_events_map_title_params = dict()

# %%
# call the task


set_events_map_title = (
    set_string_var.set_task_instance_id("set_events_map_title")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(var="Events Map", **set_events_map_title_params)
    .call()
)


# %% [markdown]
# ## Set Pie Chart Title

# %%
# parameters

set_pie_chart_title_params = dict()

# %%
# call the task


set_pie_chart_title = (
    set_string_var.set_task_instance_id("set_pie_chart_title")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(var="Events Pie Chart", **set_pie_chart_title_params)
    .call()
)


# %% [markdown]
# ## Set Feature Denisty Map Title

# %%
# parameters

set_fd_map_title_params = dict()

# %%
# call the task


set_fd_map_title = (
    set_string_var.set_task_instance_id("set_fd_map_title")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(var="Density Map", **set_fd_map_title_params)
    .call()
)


# %% [markdown]
# ## Split Events by Group

# %%
# parameters

split_event_groups_params = dict()

# %%
# call the task


split_event_groups = (
    split_groups.set_task_instance_id("split_event_groups")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=events_colormap, groupers=resolved_groupers, **split_event_groups_params
    )
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

events_bar_chart_params = dict(
    time_interval=...,
)

# %%
# call the task


events_bar_chart = (
    draw_time_series_bar_chart.set_task_instance_id("events_bar_chart")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        x_axis="time",
        y_axis="event_type_display",
        category="event_type_display",
        agg_function="count",
        color_column="event_type_colormap",
        plot_style={"xperiodalignment": "middle"},
        layout_style=None,
        widget_id=set_bar_chart_title,
        **events_bar_chart_params,
    )
    .mapvalues(argnames=["dataframe"], argvalues=split_event_groups)
)


# %% [markdown]
# ## Persist Bar Chart as Text

# %%
# parameters

events_bar_chart_html_url_params = dict(
    filename=...,
)

# %%
# call the task


events_bar_chart_html_url = (
    persist_text.set_task_instance_id("events_bar_chart_html_url")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        filename_suffix="v2",
        **events_bar_chart_html_url_params,
    )
    .mapvalues(argnames=["text"], argvalues=events_bar_chart)
)


# %% [markdown]
# ## Create Bar Plot Widget for Events

# %%
# parameters

events_bar_chart_widget_params = dict()

# %%
# call the task


events_bar_chart_widget = (
    create_plot_widget_single_view.set_task_instance_id("events_bar_chart_widget")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            never,
        ],
        unpack_depth=1,
    )
    .partial(title=set_bar_chart_title, **events_bar_chart_widget_params)
    .map(argnames=["view", "data"], argvalues=events_bar_chart_html_url)
)


# %% [markdown]
# ## Merge Bar Plot Widget Views

# %%
# parameters

grouped_bar_plot_widget_merge_params = dict()

# %%
# call the task


grouped_bar_plot_widget_merge = (
    merge_widget_views.set_task_instance_id("grouped_bar_plot_widget_merge")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(widgets=events_bar_chart_widget, **grouped_bar_plot_widget_merge_params)
    .call()
)


# %% [markdown]
# ## Rename columns for map tooltip display

# %%
# parameters

rename_display_columns_params = dict()

# %%
# call the task


rename_display_columns = (
    map_columns.set_task_instance_id("rename_display_columns")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        drop_columns=[],
        retain_columns=[],
        rename_columns={
            "serial_number": "Event Serial",
            "time": "Event Time",
            "event_type_display": "Event Type",
            "reported_by_name": "Reported By",
        },
        **rename_display_columns_params,
    )
    .mapvalues(argnames=["df"], argvalues=split_event_groups)
)


# %% [markdown]
# ## Map Base Layers

# %%
# parameters

base_map_defs_params = dict(
    base_maps=...,
)

# %%
# call the task


base_map_defs = (
    set_base_maps.set_task_instance_id("base_map_defs")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(**base_map_defs_params)
    .call()
)


# %% [markdown]
# ## Create map layer from grouped Events

# %%
# parameters

grouped_events_map_layer_params = dict(
    zoom=...,
)

# %%
# call the task


grouped_events_map_layer = (
    create_point_layer.set_task_instance_id("grouped_events_map_layer")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
            all_geometry_are_none,
        ],
        unpack_depth=1,
    )
    .partial(
        layer_style={"fill_color_column": "event_type_colormap", "get_radius": 5},
        legend={"label_column": "Event Type", "color_column": "event_type_colormap"},
        tooltip_columns=["Event Serial", "Event Time", "Event Type", "Reported By"],
        **grouped_events_map_layer_params,
    )
    .mapvalues(argnames=["geodataframe"], argvalues=rename_display_columns)
)


# %% [markdown]
# ## Draw Ecomap from grouped Events

# %%
# parameters

grouped_events_ecomap_params = dict(
    view_state=...,
)

# %%
# call the task


grouped_events_ecomap = (
    draw_ecomap.set_task_instance_id("grouped_events_ecomap")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        title=None,
        tile_layers=base_map_defs,
        north_arrow_style={"placement": "top-left"},
        legend_style={
            "title": "Event Type",
            "format_title": False,
            "placement": "bottom-right",
        },
        static=False,
        max_zoom=20,
        widget_id=set_events_map_title,
        **grouped_events_ecomap_params,
    )
    .mapvalues(argnames=["geo_layers"], argvalues=grouped_events_map_layer)
)


# %% [markdown]
# ## Persist grouped Events Ecomap as Text

# %%
# parameters

grouped_events_ecomap_html_url_params = dict(
    filename=...,
)

# %%
# call the task


grouped_events_ecomap_html_url = (
    persist_text.set_task_instance_id("grouped_events_ecomap_html_url")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        filename_suffix="v2",
        **grouped_events_ecomap_html_url_params,
    )
    .mapvalues(argnames=["text"], argvalues=grouped_events_ecomap)
)


# %% [markdown]
# ## Create grouped Events Map Widget

# %%
# parameters

grouped_events_map_widget_params = dict()

# %%
# call the task


grouped_events_map_widget = (
    create_map_widget_single_view.set_task_instance_id("grouped_events_map_widget")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            never,
        ],
        unpack_depth=1,
    )
    .partial(title=set_events_map_title, **grouped_events_map_widget_params)
    .map(argnames=["view", "data"], argvalues=grouped_events_ecomap_html_url)
)


# %% [markdown]
# ## Merge Events Map Widget Views

# %%
# parameters

grouped_events_map_widget_merge_params = dict()

# %%
# call the task


grouped_events_map_widget_merge = (
    merge_widget_views.set_task_instance_id("grouped_events_map_widget_merge")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        widgets=grouped_events_map_widget, **grouped_events_map_widget_merge_params
    )
    .call()
)


# %% [markdown]
# ## Draw Pie Chart for Events

# %%
# parameters

grouped_events_pie_chart_params = dict()

# %%
# call the task


grouped_events_pie_chart = (
    draw_pie_chart.set_task_instance_id("grouped_events_pie_chart")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        value_column="event_type_display",
        color_column="event_type_colormap",
        plot_style={"textinfo": "value"},
        label_column=None,
        layout_style=None,
        widget_id=set_pie_chart_title,
        **grouped_events_pie_chart_params,
    )
    .mapvalues(argnames=["dataframe"], argvalues=split_event_groups)
)


# %% [markdown]
# ## Persist Pie Chart as Text

# %%
# parameters

grouped_pie_chart_html_urls_params = dict(
    filename=...,
)

# %%
# call the task


grouped_pie_chart_html_urls = (
    persist_text.set_task_instance_id("grouped_pie_chart_html_urls")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        filename_suffix="v2",
        **grouped_pie_chart_html_urls_params,
    )
    .mapvalues(argnames=["text"], argvalues=grouped_events_pie_chart)
)


# %% [markdown]
# ## Create Plot Widget for Events

# %%
# parameters

grouped_events_pie_chart_widgets_params = dict()

# %%
# call the task


grouped_events_pie_chart_widgets = (
    create_plot_widget_single_view.set_task_instance_id(
        "grouped_events_pie_chart_widgets"
    )
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            never,
        ],
        unpack_depth=1,
    )
    .partial(title=set_pie_chart_title, **grouped_events_pie_chart_widgets_params)
    .map(argnames=["view", "data"], argvalues=grouped_pie_chart_html_urls)
)


# %% [markdown]
# ## Merge Pie Chart Widget Views

# %%
# parameters

grouped_events_pie_widget_merge_params = dict()

# %%
# call the task


grouped_events_pie_widget_merge = (
    merge_widget_views.set_task_instance_id("grouped_events_pie_widget_merge")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        widgets=grouped_events_pie_chart_widgets,
        **grouped_events_pie_widget_merge_params,
    )
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

events_meshgrid_params = dict(
    auto_scale_or_custom_cell_size=...,
    crs=...,
)

# %%
# call the task


events_meshgrid = (
    create_meshgrid.set_task_instance_id("events_meshgrid")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
            all_geometry_are_none,
        ],
        unpack_depth=1,
    )
    .partial(
        aoi=events_add_spatial_index, intersecting_only=False, **events_meshgrid_params
    )
    .call()
)


# %% [markdown]
# ## Grouped Events Feature Density

# %%
# parameters

grouped_events_feature_density_params = dict()

# %%
# call the task


grouped_events_feature_density = (
    calculate_feature_density.set_task_instance_id("grouped_events_feature_density")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        meshgrid=events_meshgrid,
        geometry_type="point",
        sum_column=None,
        **grouped_events_feature_density_params,
    )
    .mapvalues(argnames=["geodataframe"], argvalues=split_event_groups)
)


# %% [markdown]
# ## Sort Density By Classification

# %%
# parameters

sort_grouped_density_values_params = dict()

# %%
# call the task


sort_grouped_density_values = (
    sort_values.set_task_instance_id("sort_grouped_density_values")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        column_name="density",
        ascending=True,
        na_position="last",
        **sort_grouped_density_values_params,
    )
    .mapvalues(argnames=["df"], argvalues=grouped_events_feature_density)
)


# %% [markdown]
# ## Drop nan percentiles for map display

# %%
# parameters

drop_nan_values_params = dict()

# %%
# call the task


drop_nan_values = (
    drop_nan_values_by_column.set_task_instance_id("drop_nan_values")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(column_name="density", **drop_nan_values_params)
    .mapvalues(argnames=["df"], argvalues=sort_grouped_density_values)
)


# %% [markdown]
# ## Classify Density Values

# %%
# parameters

classify_fd_params = dict()

# %%
# call the task


classify_fd = (
    apply_classification.set_task_instance_id("classify_fd")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        input_column_name="density",
        output_column_name="density_bins",
        classification_options={"scheme": "equal_interval", "k": 10},
        label_options={"label_ranges": True, "label_decimals": 0},
        **classify_fd_params,
    )
    .mapvalues(argnames=["df"], argvalues=drop_nan_values)
)


# %% [markdown]
# ## Grouped Feature Density Colormap

# %%
# parameters

grouped_fd_colormap_params = dict()

# %%
# call the task


grouped_fd_colormap = (
    apply_color_map.set_task_instance_id("grouped_fd_colormap")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        input_column_name="density_bins",
        colormap="RdYlGn_r",
        output_column_name="density_colormap",
        **grouped_fd_colormap_params,
    )
    .mapvalues(argnames=["df"], argvalues=classify_fd)
)


# %% [markdown]
# ## Create map layer from Feature Density

# %%
# parameters

grouped_fd_map_layer_params = dict(
    zoom=...,
)

# %%
# call the task


grouped_fd_map_layer = (
    create_polygon_layer.set_task_instance_id("grouped_fd_map_layer")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
            all_geometry_are_none,
        ],
        unpack_depth=1,
    )
    .partial(
        layer_style={
            "fill_color_column": "density_colormap",
            "get_line_width": 0,
            "opacity": 0.4,
        },
        legend={"label_column": "density_bins", "color_column": "density_colormap"},
        tooltip_columns=["density"],
        **grouped_fd_map_layer_params,
    )
    .mapvalues(argnames=["geodataframe"], argvalues=grouped_fd_colormap)
)


# %% [markdown]
# ## Draw Ecomap from Feature Density

# %%
# parameters

grouped_fd_ecomap_params = dict(
    view_state=...,
)

# %%
# call the task


grouped_fd_ecomap = (
    draw_ecomap.set_task_instance_id("grouped_fd_ecomap")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        title=None,
        tile_layers=base_map_defs,
        north_arrow_style={"placement": "top-left"},
        legend_style={
            "title": "Number Of Events",
            "format_title": False,
            "placement": "bottom-right",
        },
        static=False,
        max_zoom=20,
        widget_id=set_fd_map_title,
        **grouped_fd_ecomap_params,
    )
    .mapvalues(argnames=["geo_layers"], argvalues=grouped_fd_map_layer)
)


# %% [markdown]
# ## Persist Feature Density Ecomap as Text

# %%
# parameters

grouped_fd_ecomap_html_url_params = dict(
    filename=...,
)

# %%
# call the task


grouped_fd_ecomap_html_url = (
    persist_text.set_task_instance_id("grouped_fd_ecomap_html_url")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        filename_suffix="v2",
        **grouped_fd_ecomap_html_url_params,
    )
    .mapvalues(argnames=["text"], argvalues=grouped_fd_ecomap)
)


# %% [markdown]
# ## Create Feature Density Map Widget

# %%
# parameters

grouped_fd_map_widget_params = dict()

# %%
# call the task


grouped_fd_map_widget = (
    create_map_widget_single_view.set_task_instance_id("grouped_fd_map_widget")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            never,
        ],
        unpack_depth=1,
    )
    .partial(title=set_fd_map_title, **grouped_fd_map_widget_params)
    .map(argnames=["view", "data"], argvalues=grouped_fd_ecomap_html_url)
)


# %% [markdown]
# ## Merge Feature Density Widget Views

# %%
# parameters

grouped_fd_map_widget_merge_params = dict()

# %%
# call the task


grouped_fd_map_widget_merge = (
    merge_widget_views.set_task_instance_id("grouped_fd_map_widget_merge")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(widgets=grouped_fd_map_widget, **grouped_fd_map_widget_merge_params)
    .call()
)


# %% [markdown]
# ## Create Dashboard with Map Widgets

# %%
# parameters

events_dashboard_params = dict(
    warning=...,
)

# %%
# call the task


events_dashboard = (
    gather_dashboard.set_task_instance_id("events_dashboard")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        details=workflow_details,
        widgets=[
            grouped_bar_plot_widget_merge,
            grouped_events_map_widget_merge,
            grouped_events_pie_widget_merge,
            grouped_fd_map_widget_merge,
        ],
        groupers=resolved_groupers,
        time_range=time_range,
        **events_dashboard_params,
    )
    .call()
)
